{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIR TANKS STICKER TRAIN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import random\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path and model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '.'\n",
    "PATH = ROOT + \"./machine-learning/\"\n",
    "TRAIN_PATH = PATH + \"train\"\n",
    "TEST_PATH = PATH + \"test\"\n",
    "IMG_SIZE = 32\n",
    "CHANNELS = 1\n",
    "LABEL_FILE = 'labels.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the labels from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['sticker_1', 'sticker_2', 'sticker_p', 'sticker_t', 'sticker_1_180', 'sticker_2_180', 'sticker_p_180', 'sticker_t_180', 'sticker_1_90', 'sticker_2_90', 'sticker_p_90', 'sticker_t_90']\n",
      "Number of classes: 12\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "with open(PATH + LABEL_FILE, \"r\") as file:\n",
    "    labels = file.read().splitlines()\n",
    "\n",
    "num_classes = len(labels)\n",
    "print('Labels: ' + str(labels))\n",
    "print('Number of classes: ' + str(num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the images from the folder, load them into an array, convert them to gray if necessary and attach its labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add 126 images with label sticker_1 \n",
      "Add 105 images with label sticker_2 \n",
      "Add 45 images with label sticker_p \n",
      "Add 36 images with label sticker_t \n",
      "Add 105 images with label sticker_1_180 \n",
      "Add 98 images with label sticker_2_180 \n",
      "Add 45 images with label sticker_p_180 \n",
      "Add 36 images with label sticker_t_180 \n",
      "Add 106 images with label sticker_1_90 \n",
      "Add 99 images with label sticker_2_90 \n",
      "Add 90 images with label sticker_p_90 \n",
      "Add 52 images with label sticker_t_90 \n",
      "\n",
      "Total images: 943\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "dataset = []\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, CHANNELS)\n",
    "\n",
    "for folder in labels:    \n",
    "    counter = 0\n",
    "    files = os.listdir(f'../images/{labels[i]}')\n",
    "    for file in files:\n",
    "        ext = file.split('.')[-1]\n",
    "        if ext in ['jpg', 'png']:\n",
    "            img = cv.imread(f'../images/{labels[i]}/{file}')\n",
    "            if CHANNELS == 1:\n",
    "                img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "            img = cv.resize(img, input_shape[:2])\n",
    "            dataset.append([img, i])\n",
    "            counter += 1\n",
    "    print(f'Add {counter} images with label {labels[i]} ')\n",
    "    i += 1\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for image, label in dataset:\n",
    "    X.append(image)\n",
    "    y.append(label)\n",
    "\n",
    "print(f'\\nTotal images: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: sticker_1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0,len(dataset) - 1)\n",
    "image = dataset[index][0]\n",
    "label = labels[dataset[index][1]]\n",
    "plt.imshow(image, cmap='gray')\n",
    "print(f'Label: {label}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the images to tensors and normalize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, CHANNELS)\n",
    "X = X / 255\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "x_train_mean = np.mean(X_train, axis=0)\n",
    "X_train -= x_train_mean\n",
    "X_test -= x_train_mean\n",
    "\n",
    "y_cat_train = to_categorical(y_train, num_classes)\n",
    "y_cat_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Conv2D(filters=32, kernel_size=(3,3), input_shape=input_shape, activation=\"relu\")\n",
    ")\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation=\"softmax\", kernel_initializer='he_normal'))\n",
    "\n",
    "\n",
    "log_dir = 'logs\\\\fit'\n",
    "\n",
    "board = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=2,\n",
    "    embeddings_freq=1\n",
    ")\n",
    "\n",
    "# Compile and Train\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  2/191 [..............................] - ETA: 26s - loss: 2.5376 - accuracy: 0.0000e+00WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.139502). Check your callbacks.\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 1.9126 - accuracy: 0.3486 - val_loss: 1.3025 - val_accuracy: 0.6118\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 0.7786 - accuracy: 0.7641 - val_loss: 0.5998 - val_accuracy: 0.8118\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 0.4239 - accuracy: 0.8650 - val_loss: 0.3777 - val_accuracy: 0.8706\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 0.2436 - accuracy: 0.9279 - val_loss: 0.2715 - val_accuracy: 0.9059\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 0.1617 - accuracy: 0.9450 - val_loss: 0.1329 - val_accuracy: 0.9529\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 0.0915 - accuracy: 0.9738 - val_loss: 0.1196 - val_accuracy: 0.9765\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 0.0747 - accuracy: 0.9817 - val_loss: 0.1974 - val_accuracy: 0.9059\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 0.1249 - accuracy: 0.9659 - val_loss: 0.1642 - val_accuracy: 0.9412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fd876bc1c8>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "epochs = 10\n",
    "callbacks = [EarlyStopping(patience=2), board]\n",
    "\n",
    "model.fit(X_train, y_cat_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_split=0.1, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2279 - accuracy: 0.9263\n",
      "LOSS: 0.22789764404296875, ACC: 92.63157844543457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       0.90      0.82      0.86        11\n",
      "           2       1.00      1.00      1.00         6\n",
      "           3       0.75      0.75      0.75         4\n",
      "           4       0.80      1.00      0.89         8\n",
      "           5       0.92      0.92      0.92        12\n",
      "           6       1.00      1.00      1.00         4\n",
      "           7       0.80      0.80      0.80         5\n",
      "           8       0.90      0.90      0.90        10\n",
      "           9       1.00      0.90      0.95        10\n",
      "          10       1.00      1.00      1.00         7\n",
      "          11       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.93        95\n",
      "   macro avg       0.92      0.92      0.92        95\n",
      "weighted avg       0.93      0.93      0.93        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_cat_test)\n",
    "\n",
    "print(\"LOSS: {}, ACC: {}\".format(loss, acc * 100))\n",
    "\n",
    "pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING PROCESS DONE!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "str_date = now.strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "file_name = f\"../models/stickers_{IMG_SIZE}x{IMG_SIZE}.h5\"\n",
    "\n",
    "model.save(file_name)\n",
    "\n",
    "print(\"TRAINING PROCESS DONE!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 28212."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %cd ..\n",
    "%tensorboard --logdir ../logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Work\\Projects\\opencv-tanks\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
