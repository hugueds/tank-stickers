{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIR TANKS STICKER TRAIN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import random\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path and model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '.'\n",
    "PATH = ROOT + \"./machine-learning/\"\n",
    "TRAIN_PATH = PATH + \"train\"\n",
    "TEST_PATH = PATH + \"test\"\n",
    "IMG_SIZE = 32\n",
    "CHANNELS = 1\n",
    "LABEL_FILE = 'labels.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the labels from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['sticker_1', 'sticker_2', 'sticker_p', 'sticker_t', 'sticker_1_180', 'sticker_2_180', 'sticker_p_180', 'sticker_t_180', 'sticker_1_90', 'sticker_2_90', 'sticker_p_90', 'sticker_t_90']\n",
      "Number of classes: 12\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "with open(PATH + LABEL_FILE, \"r\") as file:\n",
    "    labels = file.read().splitlines()\n",
    "\n",
    "num_classes = len(labels)\n",
    "print('Labels: ' + str(labels))\n",
    "print('Number of classes: ' + str(num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the images from the folder, load them into an array, convert them to gray if necessary and attach its labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add 126 images with label sticker_1 \n",
      "Add 105 images with label sticker_2 \n",
      "Add 45 images with label sticker_p \n",
      "Add 36 images with label sticker_t \n",
      "Add 105 images with label sticker_1_180 \n",
      "Add 98 images with label sticker_2_180 \n",
      "Add 45 images with label sticker_p_180 \n",
      "Add 36 images with label sticker_t_180 \n",
      "Add 106 images with label sticker_1_90 \n",
      "Add 99 images with label sticker_2_90 \n",
      "Add 90 images with label sticker_p_90 \n",
      "Add 52 images with label sticker_t_90 \n",
      "\n",
      "Total images: 943\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "dataset = []\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, CHANNELS)\n",
    "\n",
    "for folder in labels:    \n",
    "    counter = 0\n",
    "    files = os.listdir(f'../images/{labels[i]}')\n",
    "    for file in files:\n",
    "        ext = file.split('.')[-1]\n",
    "        if ext in ['jpg', 'png']:\n",
    "            img = cv.imread(f'../images/{labels[i]}/{file}')\n",
    "            if CHANNELS == 1:\n",
    "                img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "            img = cv.resize(img, input_shape[:2])\n",
    "            dataset.append([img, i])\n",
    "            counter += 1\n",
    "    print(f'Add {counter} images with label {labels[i]} ')\n",
    "    i += 1\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for image, label in dataset:\n",
    "    X.append(image)\n",
    "    y.append(label)\n",
    "\n",
    "print(f'\\nTotal images: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: sticker_2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0,len(dataset) - 1)\n",
    "image = dataset[index][0]\n",
    "label = labels[dataset[index][1]]\n",
    "plt.imshow(image, cmap='gray')\n",
    "print(f'Label: {label}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the images to tensors and normalize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, CHANNELS)\n",
    "X = X / 255\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "x_train_mean = np.mean(X_train, axis=0)\n",
    "X_train -= x_train_mean\n",
    "X_test -= x_train_mean\n",
    "\n",
    "y_cat_train = to_categorical(y_train, num_classes)\n",
    "y_cat_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Conv2D(filters=32, kernel_size=(3,3), input_shape=input_shape, activation=\"relu\")\n",
    ")\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation=\"softmax\", kernel_initializer='he_normal'))\n",
    "\n",
    "\n",
    "log_dir = 'logs\\\\fit'\n",
    "\n",
    "board = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=2,\n",
    "    embeddings_freq=1\n",
    ")\n",
    "\n",
    "# Compile and Train\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  2/191 [..............................] - ETA: 25s - loss: 2.4495 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0150s vs `on_train_batch_end` time: 0.2410s). Check your callbacks.\n",
      "191/191 [==============================] - 4s 23ms/step - loss: 1.8920 - accuracy: 0.3394 - val_loss: 1.3147 - val_accuracy: 0.5529\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.8749 - accuracy: 0.6841 - val_loss: 0.6812 - val_accuracy: 0.7412\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.4659 - accuracy: 0.8506 - val_loss: 0.3868 - val_accuracy: 0.8824\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.2678 - accuracy: 0.9069 - val_loss: 0.3056 - val_accuracy: 0.8824\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.1984 - accuracy: 0.9410 - val_loss: 0.2269 - val_accuracy: 0.9412\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.1238 - accuracy: 0.9685 - val_loss: 0.2311 - val_accuracy: 0.9412\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.1281 - accuracy: 0.9581 - val_loss: 0.2169 - val_accuracy: 0.9294\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.0834 - accuracy: 0.9712 - val_loss: 0.1998 - val_accuracy: 0.9529\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.0730 - accuracy: 0.9790 - val_loss: 0.1997 - val_accuracy: 0.9176\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.0504 - accuracy: 0.9882 - val_loss: 0.1620 - val_accuracy: 0.9529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16e6457e508>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "epochs = 10\n",
    "callbacks = [EarlyStopping(patience=2), board]\n",
    "\n",
    "model.fit(X_train, y_cat_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_split=0.1, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1535 - accuracy: 0.9474\n",
      "LOSS: 0.15346665680408478, ACC: 94.73684430122375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        12\n",
      "           1       0.90      0.82      0.86        11\n",
      "           2       1.00      1.00      1.00         6\n",
      "           3       1.00      0.75      0.86         4\n",
      "           4       0.80      1.00      0.89         8\n",
      "           5       1.00      0.92      0.96        12\n",
      "           6       1.00      1.00      1.00         4\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       1.00      1.00      1.00        10\n",
      "           9       1.00      0.90      0.95        10\n",
      "          10       1.00      1.00      1.00         7\n",
      "          11       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.95        95\n",
      "   macro avg       0.96      0.95      0.95        95\n",
      "weighted avg       0.95      0.95      0.95        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_cat_test)\n",
    "\n",
    "print(\"LOSS: {}, ACC: {}\".format(loss, acc * 100))\n",
    "\n",
    "pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING PROCESS DONE!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "str_date = now.strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "file_name = f\"../models/stickers_{IMG_SIZE}x{IMG_SIZE}.h5\"\n",
    "\n",
    "model.save(file_name)\n",
    "\n",
    "print(\"TRAINING PROCESS DONE!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "# %cd ..\n",
    "%tensorboard --logdir ../logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
