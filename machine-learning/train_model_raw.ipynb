{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIR TANKS STICKER TRAIN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import random\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path and model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '.'\n",
    "PATH = ROOT + \"./machine-learning/\"\n",
    "TRAIN_PATH = PATH + \"train\"\n",
    "TEST_PATH = PATH + \"test\"\n",
    "IMG_SIZE = 32\n",
    "CHANNELS = 1\n",
    "LABEL_FILE = 'labels.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the labels from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['sticker_1', 'sticker_2', 'sticker_p', 'sticker_t', 'sticker_1_180', 'sticker_2_180', 'sticker_p_180', 'sticker_t_180', 'sticker_1_90', 'sticker_2_90', 'sticker_p_90', 'sticker_t_90']\n",
      "Number of classes: 12\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "with open(PATH + LABEL_FILE, \"r\") as file:\n",
    "    labels = file.read().splitlines()\n",
    "\n",
    "num_classes = len(labels)\n",
    "print('Labels: ' + str(labels))\n",
    "print('Number of classes: ' + str(num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the images from the folder, load them into an array, convert them to gray if necessary and attach its labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add 126 images with label sticker_1 \n",
      "Add 105 images with label sticker_2 \n",
      "Add 45 images with label sticker_p \n",
      "Add 36 images with label sticker_t \n",
      "Add 105 images with label sticker_1_180 \n",
      "Add 98 images with label sticker_2_180 \n",
      "Add 45 images with label sticker_p_180 \n",
      "Add 36 images with label sticker_t_180 \n",
      "Add 106 images with label sticker_1_90 \n",
      "Add 99 images with label sticker_2_90 \n",
      "Add 90 images with label sticker_p_90 \n",
      "Add 52 images with label sticker_t_90 \n",
      "\n",
      "Total images: 943\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "dataset = []\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, CHANNELS)\n",
    "\n",
    "for folder in labels:    \n",
    "    counter = 0\n",
    "    files = os.listdir(f'../images/{labels[i]}')\n",
    "    for file in files:\n",
    "        ext = file.split('.')[-1]\n",
    "        if ext in ['jpg', 'png']:\n",
    "            img = cv.imread(f'../images/{labels[i]}/{file}')\n",
    "            if CHANNELS == 1:\n",
    "                img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "            img = cv.resize(img, input_shape[:2])\n",
    "            dataset.append([img, i])\n",
    "            counter += 1\n",
    "    print(f'Add {counter} images with label {labels[i]} ')\n",
    "    i += 1\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for image, label in dataset:\n",
    "    X.append(image)\n",
    "    y.append(label)\n",
    "\n",
    "print(f'\\nTotal images: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: sticker_1_90\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0,len(dataset) - 1)\n",
    "image = dataset[index][0]\n",
    "label = labels[dataset[index][1]]\n",
    "plt.imshow(image, cmap='gray')\n",
    "print(f'Label: {label}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the images to tensors and normalize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, CHANNELS)\n",
    "X = X / 255\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "x_train_mean = np.mean(X_train, axis=0)\n",
    "X_train -= x_train_mean\n",
    "X_test -= x_train_mean\n",
    "\n",
    "y_cat_train = to_categorical(y_train, num_classes)\n",
    "y_cat_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Conv2D(filters=32, kernel_size=(3,3), input_shape=input_shape, activation=\"relu\")\n",
    ")\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation=\"softmax\", kernel_initializer='he_normal'))\n",
    "\n",
    "\n",
    "log_dir = 'logs\\\\fit'\n",
    "\n",
    "board = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=2,\n",
    "    embeddings_freq=1\n",
    ")\n",
    "\n",
    "# Compile and Train\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  2/191 [..............................] - ETA: 46s - loss: 2.5525 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0190s vs `on_train_batch_end` time: 0.4600s). Check your callbacks.\n",
      "191/191 [==============================] - 5s 24ms/step - loss: 1.9108 - accuracy: 0.3434 - val_loss: 1.2976 - val_accuracy: 0.6353\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.7563 - accuracy: 0.7497 - val_loss: 0.6239 - val_accuracy: 0.8235\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.3978 - accuracy: 0.8820 - val_loss: 0.4719 - val_accuracy: 0.8353\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.2633 - accuracy: 0.9148 - val_loss: 0.3104 - val_accuracy: 0.8941\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 4s 21ms/step - loss: 0.1898 - accuracy: 0.9423 - val_loss: 0.3065 - val_accuracy: 0.8941\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.0974 - accuracy: 0.9738 - val_loss: 0.2396 - val_accuracy: 0.9059\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 4s 21ms/step - loss: 0.0838 - accuracy: 0.9738 - val_loss: 0.2182 - val_accuracy: 0.9176\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 4s 21ms/step - loss: 0.0500 - accuracy: 0.9856 - val_loss: 0.2282 - val_accuracy: 0.9176\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.0610 - accuracy: 0.9882 - val_loss: 0.1548 - val_accuracy: 0.9294\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.0936 - accuracy: 0.9817 - val_loss: 0.3848 - val_accuracy: 0.8706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19ed8a3eec8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "epochs = 10\n",
    "callbacks = [EarlyStopping(patience=2), board]\n",
    "\n",
    "model.fit(X_train, y_cat_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_split=0.1, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3175 - accuracy: 0.9158\n",
      "LOSS: 0.31749677658081055, ACC: 91.57894849777222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        12\n",
      "           1       0.69      0.82      0.75        11\n",
      "           2       1.00      1.00      1.00         6\n",
      "           3       0.80      1.00      0.89         4\n",
      "           4       0.89      1.00      0.94         8\n",
      "           5       1.00      0.67      0.80        12\n",
      "           6       1.00      1.00      1.00         4\n",
      "           7       1.00      0.80      0.89         5\n",
      "           8       1.00      1.00      1.00        10\n",
      "           9       1.00      0.90      0.95        10\n",
      "          10       1.00      1.00      1.00         7\n",
      "          11       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.92        95\n",
      "   macro avg       0.94      0.93      0.93        95\n",
      "weighted avg       0.93      0.92      0.92        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_cat_test)\n",
    "\n",
    "print(\"LOSS: {}, ACC: {}\".format(loss, acc * 100))\n",
    "\n",
    "pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING PROCESS DONE!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "str_date = now.strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "file_name = f\"../models/stickers_{IMG_SIZE}x{IMG_SIZE}.h5\"\n",
    "\n",
    "model.save(file_name)\n",
    "\n",
    "print(\"TRAINING PROCESS DONE!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "# %cd ..\n",
    "%tensorboard --logdir ../logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
